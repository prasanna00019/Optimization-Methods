{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c5e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_at_point(f, vars_list, point):\n",
    "    subs_dict = dict(zip(vars_list, point))\n",
    "    result = f.subs(subs_dict).evalf() \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61853810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[1, -1], grad=[800.000000000000, -400.000000000000]\n",
      "  alpha=0.0015448525817269945\n",
      "Iter 1: point=[-0.235882065381596, -0.382058967309202], grad=[-43.7699316077890, -87.5398632155779]\n",
      "  alpha=0.0042667136310861106\n",
      "Iter 2: point=[-0.0899992989090106, 0.0118840590111551], grad=[-2.04376899158778, 0.756837041408339]\n",
      "  alpha=0.052467087054339896\n",
      "Iter 3: point=[0.0181208159695501, -0.0254229377324494], grad=[-1.77710452840016, -5.15026034077034]\n",
      "  alpha=0.00808501143062263\n",
      "Iter 4: point=[0.136609486165860, -0.0197100376809510], grad=[0.370021002661824, -7.67443787829028]\n",
      "  alpha=0.0036610970341403237\n",
      "Iter 5: point=[0.241962826251575, 0.0135317233153973], grad=[2.84063919472031, -9.00285719445054]\n",
      "  alpha=0.002596741453173269\n",
      "Iter 6: point=[0.347395135361122, 0.0725039443472915], grad=[5.38971090888482, -9.63588714505618]\n",
      "  alpha=0.002284427272727904\n",
      "Iter 7: point=[0.461948700299809, 0.165477292978408], grad=[7.77840235548588, -9.58386174605492]\n",
      "  alpha=0.002480042987743438\n",
      "Iter 8: point=[0.598090834849761, 0.315397302410205], grad=[9.31954951447946, -8.46306886421601]\n",
      "  alpha=0.0040745573087320125\n",
      "Iter 9: point=[0.792781038755566, 0.606089821220838], grad=[6.69267100667383, -4.48239083790322]\n",
      "  alpha=0.0018706893785756559\n",
      "Iter 10: point=[0.816857083137911, 0.669116507650141], grad=[-0.974358617435342, 0.372202675512881]\n",
      "  alpha=0.0017601855863490941\n",
      "Iter 11: point=[0.818951973890440, 0.669455710352554], grad=[0.0397227948621151, -0.245325037298812]\n",
      "  alpha=0.006957765416195599\n",
      "Iter 12: point=[0.819145706012036, 0.671238744822617], grad=[-0.440037641392024, 0.0478114289321070]\n",
      "  alpha=0.05487917186215895\n",
      "Iter 13: point=[0.848141828197298, 0.713226812821465], grad=[1.77177081729741, -1.22354958327796]\n",
      "  alpha=0.00926540796063697\n",
      "Iter 14: point=[0.947573144340118, 0.892317396813913], grad=[2.00916948874624, -1.11549341214086]\n",
      "  alpha=0.0018399141109438175\n",
      "Iter 15: point=[0.966367671887280, 0.934879852458149], grad=[-0.458981865200769, 0.202675037861269]\n",
      "  alpha=0.0014431135543000809\n",
      "Iter 16: point=[0.967732728205795, 0.936178702544135], grad=[0.0624051634449074, -0.0655861392993700]\n",
      "  alpha=0.0016817886203127452\n",
      "Iter 17: point=[0.967679568273203, 0.936338284960499], grad=[-0.0393024089442520, -0.0130923785827974]\n",
      "  alpha=0.009231271129986899\n",
      "Iter 18: point=[0.967981283094958, 0.936642551309635], grad=[0.0696264988318944, -0.0690426225053784]\n",
      "  alpha=0.03867740535164264\n",
      "Iter 19: point=[0.972370861781195, 0.946455387187990], grad=[-0.424873689648507, 0.190058869377168]\n",
      "  alpha=0.005628561138138452\n",
      "Iter 20: point=[0.989155721376883, 0.977561925992543], grad=[0.321396203514269, -0.173423028015719]\n",
      "  alpha=0.0018760367758773096\n",
      "Iter 21: point=[0.991996940415671, 0.984270181815939], grad=[-0.100227461691816, 0.0424504043772060]\n",
      "  alpha=0.0016054950085607426\n",
      "Iter 22: point=[0.992373848459086, 0.984711998678345], grad=[0.0220039624439892, -0.0187712854302049]\n",
      "  alpha=0.001743623029743771\n",
      "Stopped: step norm small\n",
      "Final point: [0.992364384232651, 0.984778608507458]\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, diff, atan, N , solve\n",
    "\n",
    "def conjugate_gradient_method(eval_fun, start_pt, epsilon1, epsilon2, epsilon3):\n",
    "    n_variables = len(start_pt)\n",
    "    vars_list = symbols(f'x1:{n_variables + 1}')\n",
    "    grad_f = [diff(eval_fun, var) for var in vars_list]\n",
    "    eval_pt = start_pt[:]  # Copy list\n",
    "    prev_pt = eval_pt\n",
    "    max_iters = 400\n",
    "    i = 0\n",
    "    while i < max_iters:\n",
    "\n",
    "        grad_f_eval = [g.subs(dict(zip(vars_list, eval_pt))).evalf() for g in grad_f]\n",
    "        grad_f_prev= None\n",
    "        if(i!=0):\n",
    "         grad_f_prev = [g.subs(dict(zip(vars_list, prev_pt))).evalf() for g in grad_f]\n",
    "        print(f\"Iter {i}: point={eval_pt}, grad={grad_f_eval}\")\n",
    "\n",
    "        if all(abs(g) <= epsilon3[j] for j, g in enumerate(grad_f_eval)):  \n",
    "            print(\"Stopped: gradient small\")\n",
    "            return eval_pt\n",
    "        if(i==0):\n",
    "         s = [-val for val in grad_f_eval]\n",
    "        elif(i!=0):\n",
    "         s= [- grad_f_eval[i]  + ( sum(gi**2 for gi in grad_f_eval)/ (sum(gi**2 for gi in grad_f_prev))) * s[i] for i in range(len(s))]\n",
    "        lambda_sym = symbols('lambda')\n",
    "        subs_dict = {vars_list[j]: eval_pt[j] + lambda_sym * s[j] for j in range(n_variables)}\n",
    "        g = eval_fun.subs(subs_dict)\n",
    "        dg = diff(g, lambda_sym)\n",
    "        lambda_opts = solve(dg, lambda_sym)\n",
    "        real_opts = []\n",
    "        alpha = 0.001\n",
    "        for l in lambda_opts:\n",
    "            num_l = N(l)\n",
    "            real_part, imag_part = num_l.as_real_imag()\n",
    "            if abs(imag_part) < 1e-10:\n",
    "                real_opts.append(float(real_part))\n",
    "        positive_opts = [l for l in real_opts if l > 0]\n",
    "        if positive_opts:\n",
    "            alpha = positive_opts[0]\n",
    "        else:\n",
    "            alpha = max(real_opts) if real_opts else 0.001\n",
    "        print(f\"  alpha={alpha}\")\n",
    "        x_i1 = [eval_pt[j] + alpha * s[j] for j in range(n_variables)]\n",
    "        norm_change = sum(abs(x_i1[j] - eval_pt[j]) for j in range(n_variables))\n",
    "        if norm_change <= epsilon1:\n",
    "            print(\"Stopped: step norm small\")\n",
    "            return x_i1\n",
    "        f_old = eval_at_point(eval_fun, vars_list, eval_pt)\n",
    "        f_new = eval_at_point(eval_fun, vars_list, x_i1)\n",
    "        rel_change = abs((f_new - f_old) / f_old) if abs(f_old) > 1e-10 else abs(f_new - f_old)\n",
    "        if rel_change <= epsilon2:\n",
    "            print(\"Stopped: relative f change small\")\n",
    "            return x_i1\n",
    "        prev_pt = eval_pt\n",
    "        eval_pt = x_i1\n",
    "        i += 1\n",
    "    print(\"Stopped: max iters reached\")\n",
    "    return eval_pt\n",
    "\n",
    "x1, x2 = symbols('x1 x2')\n",
    "a, b = 1, 100\n",
    "f = (a - x1)**2 + b * (x2 - x1**2)**2\n",
    "start_pt = [1, -1]\n",
    "# start_pt = [-10,10]\n",
    "result = conjugate_gradient_method(f, start_pt, 0.0001, 0.0001, [0, 0])\n",
    "print(\"Final point:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744ed14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[1, -1], grad=[3.00000000000000, -1.00000000000000]\n",
      "  alpha=0.38461538461538464\n",
      "Iter 1: point=[-0.153846153846154, -0.615384615384615], grad=[-0.846153846153847, -2.53846153846154]\n",
      "  alpha=0.6500000000000005\n",
      "Iter 2: point=[-1.00000000000000, 1.50000000000000], grad=[8.88178419700125e-16, 2.22044604925031e-15]\n",
      "  alpha=0.26415094339622647\n",
      "Stopped: step norm small\n",
      "Final point: [-1.00000000000000, 1.50000000000000]\n"
     ]
    }
   ],
   "source": [
    "f = x1 - x2 + 2*x1**2 + 2*x1*x2 + x2**2\n",
    "start_pt = [1,-1]\n",
    "result = conjugate_gradient_method(f, start_pt, 0.0001, 0.0001, [0, 0])\n",
    "print(\"Final point:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79c63999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[-10.0, 20.0], grad=[-46800.0000000000, 64000.0000000000]\n",
      "  alpha=0.00026710203571059514\n",
      "Iter 1: point=[2.50037527125585, 2.90546971452191], grad=[295.430936492138, 216.033872309878]\n",
      "  alpha=0.0006038528390528756\n",
      "Iter 2: point=[2.32258064516129, 2.77419354838710], grad=[1.36424205265939e-12, -3.63797880709171e-12]\n",
      "  alpha=0.00021024464831804267\n",
      "Stopped: step norm small\n",
      "Final point: [2.32258064516129, 2.77419354838710]\n"
     ]
    }
   ],
   "source": [
    "f = 700*(x1 - 2)**2 + 500*(x1 - x2)**2 + 1000* (x2 - 3)**2\n",
    "start_pt = [-10.0,20.0]\n",
    "result = conjugate_gradient_method(f, start_pt, 0.0001, 0.0001, [0,0])\n",
    "print(\"Final point:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbc0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[56.0], grad=[863548060816.000]\n",
      "  alpha=6.370000593251759e-11\n",
      "Iter 1: point=[0.991983403006742], grad=[3.98969746129296e-12]\n",
      "  alpha=0.008116677263870602\n",
      "Stopped: step norm small\n",
      "Final point: [0.991983403006710]\n"
     ]
    }
   ],
   "source": [
    "f = x1**4 - 5*x1**2 + 4*x1**7  - 7 * x1**3\n",
    "start_pt = [56.0]\n",
    "result = conjugate_gradient_method(f, start_pt, 0.0001, 0.0001, [0])\n",
    "print(\"Final point:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a557567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[10.0], grad=[63040900.0000000]\n",
      "  alpha=1.4769775302969807e-07\n",
      "Iter 1: point=[0.689000721030107], grad=[-1.04805053524615e-12]\n",
      "Stopped: gradient small\n",
      "Final point: [0.689000721030107]\n"
     ]
    }
   ],
   "source": [
    "f =  x1**4 - 5 * x1**2 + 9 * x1**7 - 10 * x1**3 + 10 * x1**4\n",
    "start_pt = [10.0]\n",
    "result = conjugate_gradient_method(f, start_pt, 1e-12, 1e-12, [1e-5])\n",
    "print(\"Final point:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10587573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[10.0], grad=[77035861.0000000]\n",
      "  alpha=1.1954646398124277e-07\n",
      "Iter 1: point=[0.790635217699476], grad=[-6.14619466432487e-13]\n",
      "Stopped: gradient small\n",
      "Final point: [0.790635217699476]\n"
     ]
    }
   ],
   "source": [
    "f = x1**8 -5*x1**6 + 9*x1**4 - 7*x1**2 + x1\n",
    "start_pt = [10.0]\n",
    "result = conjugate_gradient_method(f, start_pt, 1e-12, 1e-12, [1e-5])\n",
    "print(\"Final point:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a84d2984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[-10.0], grad=[-549993001160.000]\n",
      "  alpha=1.6415054916392928e-11\n",
      "Iter 1: point=[-0.971834682326840], grad=[6.68975985718134e-12]\n",
      "Stopped: gradient small\n",
      "Final point: [-0.971834682326840]\n"
     ]
    }
   ],
   "source": [
    "f = x1**7 -5*x1**11 + 9*x1**3 - 7*x1**2 + x1**4\n",
    "start_pt = [-10.0]\n",
    "result = conjugate_gradient_method(f, start_pt, 1e-12, 1e-12, [1e-5])\n",
    "print(\"Final point:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8854224a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[-5000], grad=[-6.25985312500000e+26]\n",
      "  alpha=7.986107583031134e-24\n",
      "Iter 1: point=[-0.813948977635846], grad=[1.56806834183953e-9]\n",
      "  alpha=0.0019743069798630586\n",
      "Stopped: relative f change small\n",
      "Final point: [-0.813948977638942]\n"
     ]
    }
   ],
   "source": [
    "f = x1**8 -5*x1**2 - 9*x1**7 + 60*x1**3 +50* x1**6\n",
    "start_pt = [-5000]\n",
    "result = conjugate_gradient_method(f, start_pt, 1e-12, 1e-12, [0.0])\n",
    "print(\"Final point:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
