{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1abfd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_at_point(f, vars_list, point):\n",
    "    subs_dict = dict(zip(vars_list, point))\n",
    "    result = f.subs(subs_dict).evalf() \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c078a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[1, -1], grad=[3.00000000000000, -1.00000000000000]\n",
      "  lambda_opt=0.384615384615385\n",
      "Iter 1: point=[-0.153846153846154, -0.615384615384615], grad=[-0.846153846153847, -2.53846153846154]\n",
      "  lambda_opt=0.294117647058823\n",
      "Iter 2: point=[0.0950226244343891, 0.131221719457014], grad=[1.64253393665158, -0.547511312217195]\n",
      "  lambda_opt=0.384615384615384\n",
      "Iter 3: point=[-0.536721197354681, 0.341802993386704], grad=[-0.463278802645317, -1.38983640793595]\n",
      "  lambda_opt=0.294117647058824\n",
      "Iter 4: point=[-0.400462725988411, 0.750578407485515], grad=[0.899305911017386, -0.299768637005792]\n",
      "  lambda_opt=0.384615384615382\n",
      "Iter 5: point=[-0.746349614841249, 0.865874037103126], grad=[-0.253650385158743, -0.760951155476245]\n",
      "  lambda_opt=0.294117647058826\n",
      "Iter 6: point=[-0.671746560382794, 1.08968320047849], grad=[0.492380159425812, -0.164126719808599]\n",
      "  lambda_opt=0.384615384615378\n",
      "Iter 7: point=[-0.861123544777334, 1.15280886194334], grad=[-0.138876455222658, -0.416629365667990]\n",
      "  lambda_opt=0.294117647058827\n",
      "Iter 8: point=[-0.820277528535376, 1.27534691066922], grad=[0.269583707196938, -0.0898612357323110]\n",
      "  lambda_opt=0.384615384615380\n",
      "Iter 9: point=[-0.923963569764966, 1.30990892441242], grad=[-0.0760364302350309, -0.228109290705099]\n",
      "  lambda_opt=0.294117647058826\n",
      "Iter 10: point=[-0.901599913813486, 1.37699989226686], grad=[0.147600129279772, -0.0492000430932564]\n",
      "  lambda_opt=0.384615384615381\n",
      "Iter 11: point=[-0.958369194305705, 1.39592298576426], grad=[-0.0416308056942936, -0.124892417082883]\n",
      "  lambda_opt=0.294117647058826\n",
      "Iter 12: point=[-0.946124839689737, 1.43265604961217], grad=[0.0808127404653955, -0.0269375801551313]\n",
      "  lambda_opt=0.384615384615382\n",
      "Iter 13: point=[-0.977206662945658, 1.44301665736414], grad=[-0.0227933370543418, -0.0683800111630264]\n",
      "  lambda_opt=0.294117647058825\n",
      "Iter 14: point=[-0.970502740282616, 1.46312842535327], grad=[0.0442458895760764, -0.0147486298586914]\n",
      "  lambda_opt=0.384615384615376\n",
      "Iter 15: point=[-0.987520390119568, 1.46880097529892], grad=[-0.0124796098804310, -0.0374388296412951]\n",
      "  lambda_opt=0.294117647058827\n",
      "Iter 16: point=[-0.983849916625324, 1.47981239578165], grad=[0.0242251250620149, -0.00807504168733786]\n",
      "  lambda_opt=0.384615384615370\n",
      "Iter 17: point=[-0.993167272418406, 1.48291818104602], grad=[-0.00683272758159337, -0.0204981827447814]\n",
      "  lambda_opt=0.294117647058830\n",
      "Stopped: relative f change small\n",
      "Final point: [-0.991157646659114, 1.48894705832389]\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, diff, solve, N  \n",
    "\n",
    "def steepest_descent_method(eval_fun, start_pt, epsilon1, epsilon2, epsilon3):\n",
    "    n_variables = len(start_pt)\n",
    "    vars_list = symbols(f'x1:{n_variables + 1}')\n",
    "    grad_f = [diff(eval_fun, var) for var in vars_list]\n",
    "    eval_pt = start_pt[:] \n",
    "    max_iters = 1000\n",
    "    i = 0\n",
    "    while i < max_iters:\n",
    "        # print(i)\n",
    "        grad_f_eval = [g.subs(dict(zip(vars_list, eval_pt))).evalf() for g in grad_f]\n",
    "        print(f\"Iter {i}: point={eval_pt}, grad={grad_f_eval}\")\n",
    "        \n",
    "        if all(abs(g) <= epsilon3[j] for j, g in enumerate(grad_f_eval)):  \n",
    "            print(\"Stopped: gradient small\")\n",
    "            return eval_pt\n",
    "        \n",
    "        s = [-val for val in grad_f_eval]\n",
    "        lambda_sym = symbols('lambda')\n",
    "        subs_dict = {vars_list[j]: eval_pt[j] + lambda_sym * s[j] for j in range(n_variables)}\n",
    "        g = eval_fun.subs(subs_dict)\n",
    "        dg = diff(g, lambda_sym)\n",
    "        lambda_opts = solve(dg, lambda_sym)\n",
    "        real_opts = [N(l) for l in lambda_opts if l.is_real]  \n",
    "        positive_opts = [l for l in real_opts if float(l) > 0]\n",
    "        lambda_opt = positive_opts[0] if positive_opts else max(real_opts, key=float)  \n",
    "        print(f\"  lambda_opt={lambda_opt}\")\n",
    "        x_i1 = [eval_pt[j] + lambda_opt * s[j] for j in range(n_variables)]\n",
    "        norm_change = sum(abs(x_i1[j] - eval_pt[j]) for j in range(n_variables))\n",
    "        if norm_change <= epsilon1:\n",
    "            print(\"Stopped: step norm small\")\n",
    "            return x_i1\n",
    "        f_old = eval_at_point(eval_fun, vars_list, eval_pt)\n",
    "        f_new = eval_at_point(eval_fun, vars_list, x_i1)\n",
    "        rel_change = abs((f_new - f_old) / f_old) if abs(f_old) > 1e-10 else abs(f_new - f_old)\n",
    "        if rel_change <= epsilon2:\n",
    "            print(\"Stopped: relative f change small\")\n",
    "            return x_i1\n",
    "        eval_pt = x_i1\n",
    "        i += 1\n",
    "    print(\"Stopped: max iters reached\")\n",
    "    return eval_pt\n",
    "x1, x2 = symbols('x1 x2')\n",
    "f = x1 - x2 + 2*x1**2 + 2*x1*x2 + x2**2\n",
    "# f = 100 * (x1 - x2)**2  + (1-x1)**2\n",
    "start_pt = [1,-1] \n",
    "# start_pt = [0, 0]\n",
    "result = steepest_descent_method(f, start_pt, 0.0001, 0.0001, [0, 0])\n",
    "print(\"Final point:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813d1160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[1, -1], grad=[600.000000000000, -10000.0000000000]\n",
      "  lambda_opt=0.000320778357369336\n",
      "Iter 1: point=[0.807532985578398, 2.20778357369336], grad=[-3069.70440830521, -184.182264498313]\n",
      "  lambda_opt=0.000438100226994936\n",
      "Iter 2: point=[2.15237118366426, 2.28847386557851], grad=[77.2169752157179, -1286.94958692872]\n",
      "  lambda_opt=0.000320778357369337\n",
      "Iter 3: point=[2.12760164919354, 2.70129944009066], grad=[-395.055482026168, -23.7033289215706]\n",
      "  lambda_opt=0.000438100226994937\n",
      "Iter 4: point=[2.30067554554480, 2.71168387387173], grad=[9.93743543577739, -165.623923929601]\n",
      "  lambda_opt=0.000320778357369336\n",
      "Iter 5: point=[2.29748783132924, 2.76481244413093], grad=[-50.8416489407505, -3.05049893644536]\n",
      "  lambda_opt=0.000438100226994937\n",
      "Iter 6: point=[2.31976156927098, 2.76614886840744], grad=[1.27889784292029, -21.3149640486718]\n",
      "  lambda_opt=0.000320778357369333\n",
      "Iter 7: point=[2.31935132652169, 2.77298624756236], grad=[-6.54306391030832, -0.392583834616744]\n",
      "  lambda_opt=0.000438100226994854\n",
      "Iter 8: point=[2.32221784430603, 2.77315823862942], grad=[0.164587705066424, -2.74312841778556]\n",
      "  lambda_opt=0.000320778357369423\n",
      "Stopped: relative f change small\n",
      "Final point: [2.32216504813236, 2.77403817485733]\n"
     ]
    }
   ],
   "source": [
    "f =  700*(x1 - 2)**2 + 500*(x1 - x2)**2 + 1000* (x2 - 3)**2\n",
    "start_pt = [1,-1] \n",
    "# start_pt = [0, 0]\n",
    "result = steepest_descent_method(f, start_pt, 0.00001, 0.00001, [0, 0])\n",
    "print(\"Final point:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e4c2289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[56.0], grad=[863548060816.000]\n",
      "  lambda_opt=6.37000059325176E-11\n",
      "Iter 1: point=[0.991983403006742], grad=[3.98969746129296e-12]\n",
      "  lambda_opt=0.00811667726387060\n",
      "Stopped: step norm small\n",
      "Final point: [0.991983403006710]\n"
     ]
    }
   ],
   "source": [
    "f = x1**4 - 5*x1**2 + 4*x1**7  - 7 * x1**3\n",
    "start_pt = [56.0]\n",
    "result = steepest_descent_method(f, start_pt, 0.0001, 0.0001, [0])\n",
    "print(\"Final point:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8c8c378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[10.0], grad=[63040900.0000000]\n",
      "  lambda_opt=1.47697753029698E-7\n",
      "Iter 1: point=[0.689000721030107], grad=[-1.04805053524615e-12]\n",
      "Stopped: gradient small\n",
      "Final point: [0.689000721030107]\n"
     ]
    }
   ],
   "source": [
    "f =  x1**4 - 5 * x1**2 + 9 * x1**7 - 10 * x1**3 + 10 * x1**4\n",
    "start_pt = [10.0]\n",
    "result = steepest_descent_method(f, start_pt, 1e-12, 1e-12, [1e-5])\n",
    "print(\"Final point:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c1345cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[15.5625], grad=[1741414957.07294]\n",
      "  lambda_opt=8.48267939947512E-9\n",
      "Iter 1: point=[0.790635217699535], grad=[-1.10134124042816e-13]\n",
      "Stopped: gradient small\n",
      "Final point: [0.790635217699535]\n"
     ]
    }
   ],
   "source": [
    "f = x1**8 -5*x1**6 + 9*x1**4 - 7*x1**2 + x1\n",
    "start_pt = [15.5625]\n",
    "result = steepest_descent_method(f, start_pt, 1e-12, 1e-12, [1e-5])\n",
    "print(\"Final point:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dabb57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: point=[-78.643], grad=[-164643239577485.]\n",
      "  lambda_opt=4.72713311655490E-13\n",
      "Iter 1: point=[-0.813948977638930], grad=[5.58486590307439e-12]\n",
      "  lambda_opt=0.00194253264809085\n",
      "Stopped: step norm small\n",
      "Final point: [-0.813948977638941]\n"
     ]
    }
   ],
   "source": [
    "f = x1**8 -5*x1**2 - 9*x1**7 + 60*x1**3 +50* x1**6\n",
    "start_pt = [-78.643]\n",
    "result = steepest_descent_method(f, start_pt, 1e-12, 1e-12, [0.0])\n",
    "print(\"Final point:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
